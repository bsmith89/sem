# Topic Models

Anyone who has taken a literature class has been asked to discuss the various themes of a given text. How are such themes discovered? Upon close reading of the text, recurrent references to similar concepts might be bundled in our minds as some general theme hidden throughout the text. Discovery of such themes is part of the joy of reading in general.

One can think of these hidden, or latent, themes much as we would latent variables in factor analysis. Different texts have both different and similar themes, but the author doesn’t usually come out and announce a theme explicitly. Now consider a situation in which you have a million books. You can’t read that many, but may still want to discover the themes in them. This is what topic modeling is all about.

We don't actually analyze raw text, but what we can do is get word counts for every text, and construct a document term matrix (DTM). In this matrix, rows represent the documents and columns represent terms that are found in all documents. The values represent the counts of how many times a term is found in a text. With many texts, one will easily have thousands of columns, and most texts do not use most of the words, resulting in a very sparse matrix that is mostly zeros. Still, now that we have a numeric matrix we can perform analysis on it. The goal is just like the goal PCA and factor analysis- we want to reduce these thousands of columns of terms to a far fewer number of topics. Furthermore, like factor analysis, we will want to interpret the topics, in this case based on the terms associated with them.


## Latent Dirichlet Allocation

The most common approach to topic modeling is <span class="emph">latent dirichlet allocation</span> (LDA), which one can think of as discrete PCA. In my opinion, this should be as much a part of your toolbox as PCA and Factor Analysis, as 'compositional' data, where we have counts of occurrences (out of some total), are quite common. In the past PCA was applied to such data, but it is essentially a less performant approach with less intuitive results.

I have gone into far more detailed demonstration elsewhere, and have no desire to duplicate it.  I have [workshop notes](http://m-clark.github.io/workshops/text_analysis/) devoted exclusively to it, as well as hands-on demos [here](http://m-clark.github.io/docs/topic_models/topic-model-demo.html) and [here](http://micl.shinyapps.io/texEx/texEx.Rmd).  However we can discuss a couple things, starting with the dirichlet distribution.  A draw from the dirichlet distribution can be seen as a probability distribution for a k category event. It has one parameter, we'll call α, which is often referred to as the concentration parameter. If the k α values are equal, the resulting k probabilities will be equal on average, and with larger α, there will be less variance around that probability. When they are unequal, the larger values will result in larger probabilities assigned. Consider the following for `k=5` topics.


```{r dirichlet_draw}
library(gtools)
probs1 = rdirichlet(n=1000, alpha=rep(1,5))
probs2 = rdirichlet(n=1000, alpha=rep(100,5))
probs3 = rdirichlet(n=1000, alpha=(1:5)^2)
map(list(probs1, probs2, probs3), colMeans) %>% map(round, 2)
# one more example of where purrr can only replicate the apply family for anything meaningful, can't return a matrix, can't bind the rows... sigh
```

In topic modeling, the probabilities can represent the probability of various topics, or the probability of terms within topics. However, the thing to note is that LDA can be applied to any appropriate data, it doesn't have to be a document-term matrix resulting from text. Any count-based data matrix might potentially be appropriate.


