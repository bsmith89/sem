# Topic Models

Anyone who has taken a literature class has been asked to discuss the various themes of a given text. How are such themes discovered? Upon close reading of the text, recurrent references to similar concepts might be bundled in our minds as some general theme hidden throughout the text. Discovery of such themes is part of the joy of reading in general.

One can think of these hidden, or latent, themes much as we would latent variables in factor analysis. Different texts have both different and similar themes, but the author doesn’t usually come out and announce a theme explicitly. Now consider a situation in which you have a million books. You can’t read that many, but may still want to discover the themes in them. This is what <span class="emph">topic modeling</span> is all about.

We don't actually analyze raw text, but what we can do is get word counts for every text, and construct a <span class="emph">document term matrix</span> (DTM). In this matrix, rows represent the documents and columns represent terms that are found in all documents. The values represent the counts of how many times a term is found in a text. With many texts, one will easily have thousands of columns, and most texts do not use most of the words, resulting in a very sparse matrix that is mostly zeros. Still, now that we have a numeric matrix we can perform analysis on it. The goal is just like the goal PCA and factor analysis- we want to reduce these thousands of columns of terms to a far fewer number of topics. Furthermore, like factor analysis, we will want to interpret the topics, in this case based on the terms associated with them.


## Latent Dirichlet Allocation

The most common approach to topic modeling is <span class="emph">latent dirichlet allocation</span> (LDA), which one can think of as discrete PCA. In my opinion, this should be as much a part of your toolbox as PCA and Factor Analysis, as 'compositional' data, where we have counts of occurrences (out of some total), are quite common. In the past PCA was applied to such data, but it is essentially a less performant approach with less intuitive results.  

I have gone into far more detailed demonstration elsewhere, and have no desire to duplicate it.  I have [workshop notes](http://m-clark.github.io/workshops/text_analysis/) devoted exclusively to it, as well as hands-on demos [here](http://m-clark.github.io/docs/topic_models/topic-model-demo.html) and [here](http://micl.shinyapps.io/texEx/texEx.Rmd).  However we can discuss a couple things, starting with the dirichlet distribution.  A draw from the dirichlet distribution can be seen as a probability distribution for a k category event. It has one parameter, we'll call α, which is often referred to as the concentration parameter. If the k α values are equal, the resulting k probabilities will be equal on average, and with larger α, there will be less variance around that probability. When they are unequal, the larger values will result in larger probabilities assigned. Consider the following for `k=5` topics.


```{r dirichlet_draw, echo=1:5}
library(gtools)
probs1 = rdirichlet(n=1000, alpha=rep(1,5))
probs2 = rdirichlet(n=1000, alpha=rep(100,5))
probs3 = rdirichlet(n=1000, alpha=(1:5)^2)
map(list(probs1, probs2, probs3), colMeans) %>% map(round, 2)
# one more example of where purrr can only replicate the apply family for anything meaningful, can't return a matrix, can't bind the rows... sigh
```

In topic modeling, the probabilities can represent the probability of various topics, or the probability of terms within topics. However, the thing to note is that LDA can be applied to any appropriate data, it doesn't have to be a document-term matrix resulting from text. Any count-based data matrix might potentially be appropriate.


## Analysis

When it comes to topic modeling, most of the time is spent on processing the text itself.  Importing/scraping it, dealing with capitalization, punctuation, removing stopwords, dealing with encoding issues, removing other miscellaneous common words.  It is a highly iterative process such that once you get to the document-term matrix, you're just going to find the stuff that was missed before and repeat the process with new 'cleaning parameters' in place.  So getting to the analysis stage is the hard part.  The following image is from the [tidytext book](http://tidytextmining.com/), and depicts the process as well as some R packages that might be of use to you.


<img src="http://tidytextmining.com/images/tidyflow-ch-6.png" style="display:block; margin: 0 auto;" width=75%>


In what follows we'll start at the point of having the DTM in place and ready for analysis.  For our needs we'll use the <span class="pack">topicModels</span> package for the analysis, and mostly others for post-processing.  Due to the large number of terms, this could take a while to run depending on your machine (maybe a minute or two).  As mentioned, one of the primary results of such an analysis are the probabilities of terms within topics, which like factor loadings, can aid in interpreting the topics. The other result is the probability that a topic will be present in a given document.


```{r dtm_setup, echo=FALSE}
library(gutenbergr)

titles = c('The vision of hell. by Dante Alighieri',
           'The Divine Comedy by Dante, Illustrated, Purgatory, Complete',
           'The Divine Comedy by Dante, Illustrated, Paradise, Complete')
ids = c('The vision of hell. by Dante Alighieri',
           'The Divine Comedy by Dante, Illustrated, Purgatory, Complete',
           'The Divine Comedy by Dante, Illustrated, Paradise, Complete')
purgatory = 8795
paradise = 8799
hell = 8789
dc_books = gutenberg_works(gutenberg_id %in% c(purgatory, paradise, hell)) %>%
  gutenberg_download(meta_fields = "title") %>% 
  mutate(title = factor(title, labels=c('Paradise', 'Purgatory', 'Inferno')))   # checked

# dc_whole = gutenberg_works(gutenberg_id==8800) %>% 
#   gutenberg_download(meta_fields = c('title'))


library(tidytext)
library(stringr)

by_chapter = dc_books %>%
  group_by(title) %>%
  filter(!str_detect(text, pattern='[0-99]')) %>% # get rid of 'list of cantos
  slice(-(1:25)) %>% # get rid of title page
  mutate(chapter = cumsum(str_detect(text, regex("^canto ", ignore_case = TRUE)))) %>%
  ungroup() %>%
  filter(chapter > 0)

by_chapter_word = by_chapter %>%
  unite(title_chapter, title, chapter) %>%
  unnest_tokens(word, text)

by_chapter_bigram = by_chapter %>%
  unite(title_chapter, title, chapter) %>%
  unnest_tokens(word, text, token='ngrams', n=2)


old_stops0 = read_lines('data/topic/old_english_stop_words.txt')
old_stops = data_frame(word=str_conv(old_stops0, 'UTF8'),
                      lexicon = 'cltk')

me_stops0 = read_lines('data/topic/middle_english_stop_words.txt')
me_stops = data_frame(word=str_conv(me_stops0, 'UTF8'),
                      lexicon = 'cltk')

em_stops0 = read_lines('data/topic/early_modern_english_stop_words.txt')
em_stops = data_frame(word=str_conv(em_stops0, 'UTF8'),
                      lexicon = 'emc')

word_counts = by_chapter_word %>%
  # bind_rows(by_chapter_bigram) %>% 
  anti_join(old_stops) %>%
  anti_join(em_stops) %>%
  anti_join(me_stops) %>%
  anti_join(stop_words) %>%
  filter(word!='canto') %>% 
  count(title_chapter, word, sort = TRUE) %>%
  ungroup()



word_counts

divine_comedy_chapters_dtm = word_counts %>%
  cast_dtm(title_chapter, word, n)

# with stemming
# divine_comedy_chapters_dtm = word_counts %>%
#   cast_dfm(title_chapter, word, n) %>%
#   quanteda::dfm_wordstem()
  

divine_comedy_chapters_dtm
save('divine_comedy_chapters_dtm', file='data/topic/divine_comedy_dtm.RData')
```


The texts we'll analyze are Dante's Divine Comedy.  Each canto will be treated as a document.  I have already created the DTM where stopwords have been removed, but plenty more cleaning could have been applied.  As with factor or cluster analysis, one must choose the number of topics to retain. There are various methods/statistics that can help with this, but simple interpretabibility could be used as well.

```{r lda_divine_comedy}
load('data/topic/divine_comedy_dtm.RData')
library(topicmodels)
chapters_lda = LDA(divine_comedy_chapters_dtm, k = 3, control = list(seed = 1234))
chapters_lda
```

First, we can simply look at probable terms. The following shows the top 10 most probable terms for each topic.

```{r top_terms, echo=FALSE}
chapters_lda_td = tidy(chapters_lda)
chapters_lda_td

top_terms = chapters_lda_td %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  arrange(desc(beta)) %>% 
  ggplot(aes(term, beta)) +
  geom_point(aes(color=factor(topic)), size=3, show.legend=F) +
  facet_wrap(~ topic, scales = "free_x") +
  theme(axis.text.x = element_text(size = 8, angle = 90, hjust = 1, vjust=0)) +
  theme_trueMinimal()
# ggplotly()
```



Looking at which book would go with which topic, in this case it's more about what they don't have. For example, with the Inferno, there are few cantos that will talk about the topic where god and heaven are more probable.  Likewise, for Paradise you are less likely to find the topic containing 'beneath' and 'earth' but more likely to find the topics regarding virtue and sun and god.  Purgatory, perhaps not surpisingly is a fairly balanced mix of topics.

```{r doc_topics, echo=FALSE, fig.height=6}
chapters_lda_gamma = tidy(chapters_lda, matrix = "gamma")
# chapters_lda_gamma

chapters_lda_gamma = chapters_lda_gamma %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>% 
  mutate(title = factor(title),
         topic = factor(topic)) %>% 
  rename(canto = chapter)

# chapters_lda_gamma

chapters_lda_gamma %>% 
  group_by(title, topic) %>% 
  summarise(`Average Probability`=mean(gamma)) %>% 
  ggplot(aes(x=topic, y=`Average Probability`, fill = topic)) +
  geom_point(aes(color=topic), size=5) +
  ylim(c(0,.6)) +
  facet_wrap(~ title, nrow = 1) + 
  theme_minimal() +
  theme(axis.title.x=element_text(size=10),
        panel.grid.major.x=element_blank())
# ggplotly()
```

